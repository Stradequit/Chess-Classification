<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Predicting Chess Ratings from a Single Game : ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Predicting Chess Ratings from a Single Game</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.gatech.edu/njohnson98/chess-rating-prediction.github.io">View on GitHub</a>

          <h1 id="project_title">Predicting Chess Ratings from a Single Game</h1>
          <h2 id="project_tagline">Nathan Johnson, Oscar Aguilar, Lawson Brown, Michael Wallace, and Jeremy Benson</h2>

        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h3>
<a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Abstract</h3>
<p>	Chess is a vastly complex game with millions of players worldwide ranging in skill from beginners, who may simply know how to play the game, to grandmasters, who dedicate their lives to understanding its intricacies. This spectrum of skill levels is commonly represented with something called the Elo rating system, which is a way of ranking players in zero-sum games such as chess. While a human may be able to tell generally which end of the rating spectrum a player belongs to by watching them play, we would like to know how accurately a machine learning algorithm could analyze a single game of chess and classify its players into an appropriate rating range. Previous studies have focused on predicting the outcome of a chess game based on a history of the players’ games, as well as analyzing a player’s annotations (qualitative data) to predict their rating [5], but none that we have found have focused on classifying ratings based on a single game. We have begun to implement a long short-term memory recurrent neural network (LSTM RNN) to take in the sequence of moves, the winner, opening data, and time control information to classify the average rating of the game’s players into an Elo range. We will compare this model with our baseline, which is a Naive Bayes classifier taking in all but the sequence of moves, which is currently classifying at about 50% accuracy. We expect to increase this accuracy with the RNN to at least 80% using rating ranges of 100 Elo points.
</p>
<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Background</h3>
<p>Chess, and specifically online chess, has been booming in popularity in the past year. This is mainly due to the pandemic forcing people indoors to find new hobbies as well as the release of the Netflix show “The Queen’s Gambit” sending new players into the 64 squares. In addition, chess is one of the most famous games of all time and something that our entire team personally enjoys. <br><br>
A related game in the realm of chess is one where a player examines a single chess game, move by move, and tries to guess the Elo rating of the people who played it. This is the type of challenge that our team wants to tackle with machine learning. Upon completion, this project would allow players to succinctly summarize their performances in specific games rather than across multiple matches or tournaments. <br><br>
Chess has always been one of the most heavily studied applications of machine learning. Yet most of it has focused on developing engines to play the game, while there has been little work done in classifying the strength of the players. Previously, machine learning has been used to calculate Elo ratings for online chess players based on their overall performance in every game they have played competitively [2]. We have also found a model that tried to predict chess rating from the player’s annotation of a game [5]. However, we could not find a publication detailing a model that tackles the specific problem that we are interested in.
</p>
<h3>
<a id="creating-pages-manually" class="anchor" href="#creating-pages-manually" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Problem Definition</h3>
<p>	The problem that this project will consider is using a single chess match (the input) to try and estimate the average rating of both of the players (the output). The inputs to our primary model, the LSTM, will include the start and end times (duration) of the game, the number of turns, the game’s winner, the time increment, opening information, and the sequence of moves in standard chess notation. The inputs to our baseline, the Naive Bayes classifier, are the same, but without the sequence of moves. We want our model to output an estimate for the range of the average rating of the two players. Therefore, this is a classification problem where the classes are predetermined ranges of the rating. For example, if the classes for the model were “1 - 500”, “501 - 1000” ,”1001 - 1500”, and “1501 - 2000” and the average rating of an specific input was 1150, then we would want our model to classify that instance as “1001 - 1500”. The size of this range is parameterized in code, and we will experiment with a variety of sizes. Implicit in our model is the assumption that players of a given rating will play consistently enough so that the “noise” in their performances will look roughly normal. This would allow us to confidently predict instances into classes of narrower ranges.
</p>
<h3>
<a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Data Collection</h3>
<p>	We are using a dataset from Kaggle that includes a collection of information about thousands of online chess games played on lichess.org [1]. This dataset is perfect for our problem since it includes a wide variety of game information while covering a wide spectrum of Elo ratings. Some of the data was able to be taken directly, although we needed to apply some transformations. The most important transformation occurred in translating Unix timestamps into readable times using built-in Python functions. This allows us to see the length of games in the dataset, as well as the starting and ending times, which can be used as predictors in case the skill level of players at certain times of day should differ, for example. In addition, unnecessary columns were removed for table readability and processing, Ordinal encoding was used for binary variables, and One-Hot encoding was introduced for categorical variables. Despite this drastically increasing the dimensionality of our input, it allows us to use these variables in our classification models, hopefully producing results that are more reflective of reality. There was no need to clean the data since the dataset was procedurally pulled from real online games.
</p>
<h3>
<a id="support-or-contact" class="anchor" href="#support-or-contact" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Methods</h3>
<p>For the baseline we used a Naive Bayes Classifier. The classifier uses the result of the game, the time increment, and the opening move in order to classify players into a range of possible ratings. This is not a novel method, but it is meant to serve as a representation of how well the categorical data in our dataset can classify players. The results gained from the Naive Bayes classifier will provide insight into whether that data can or should be used in our recurrent neural network. <br><br>
	Our primary model will be a long short-term memory recurrent neural network (LSTM RNN). We have yet to fully implement this model, but it will include the sequence of moves as an input, as well as the inputs included in our baseline model. We chose an LSTM implementation because LSTMs have the ability to detect long-term dependencies and patterns within sequences of data. Since each move of a chess game directly depends on the previous moves, this model makes sense for processing the sequence of moves, as opposed to passing in the entire sequence as a single feature. LSTMs are a well-established method for learning sequential data, such as text, but we have not found examples of it being used for chess moves.
</p>
<h3>
<a id="support-or-contact" class="anchor" href="#support-or-contact" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Metrics</h3>
<p>For determining the accuracy of the Naive Bayes classifier, we simply took the number of correctly classified data points divided by the total number of data points. We also applied the metric to each of the individual features in the classifier to see if one is better at classifying than the others. This metric exactly calculates the accuracy of the classifier, but does not provide further insight into where the classifier is succeeding or failing. For this, we graphically compared the distribution of the classifier’s prediction with the distribution of the test set. This is just to show how well the Naive Bayes is classifying to provide insight into the overall accuracy metric.<br><br>
	For the RNN, we plan to use multi-class cross-entropy loss for the loss function, which is standard for nonbinary classification problems. Minimizing this loss function will allow us to train the model to classify the ratings as accurately as possible.
</p>
<h3>
<a id="support-or-contact" class="anchor" href="#support-or-contact" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results</h3>
<p>The accuracy of our Naive Bayes baseline for different rating range sizes is displayed in the “Naive Bayes Accuracy” graph. The classifier consistently outperforms random predictions, as it has a 56% accuracy across 4 classes (range 500), a 43% across 7 classes (range 300), etc. Additionally, the relative accuracy of each feature is shown in the “Individual Feature Accuracies” graph. We see that they all perform at around the same accuracy, and that the best classifier is the full Naive Bayes that takes into account all three features.
</p>
<img src="images/Naive_Bayes_Accuracy.PNG" style="width: 300px; height: auto;" id="naive-bayes-accuracy" class="graph">
<img src="images/Feature_Accuracies.PNG" style="float: right; width: 300px; height: auto;" id="feature-accuracies" class="graph">
<p>However, the Naive Bayes classifier was predominantly simply guessing whichever rating had the highest percentage of players. The individual label data shows that the classifier predicted that almost all of the players were rated 1800, neglected to classify players as less than 1500 or greater than 2100, and also rated very few players 2100 despite its significant representation in the test set.
</p>
<img src="images/Individual_Label_Accuracy.png">
<p> This isn’t unexpected as the Naive Bayes classifier takes prior probability heavily into account. However, because each feature offers so little information, the classifier overvalues prior probability. These results are subpar, mostly because a Naive Bayes classifier is not the ideal solution for this kind of problem, but also because the features didn’t provide enough information to overcome the weight of the prior probabilities. Utilizing the RNN should drastically increase the accuracy of classification.
</p>
<h3>
<a id="support-or-contact" class="anchor" href="#support-or-contact" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Conclusion</h3>
<p>	Through this project, we have begun to learn how to define a problem and plan a solution using machine learning principles. One specific example of this is data preprocessing; we have learned more about how to encode and reformat data for our problem, as well as which features in a dataset to keep and which to cast aside. Additionally, we have cemented our knowledge of Naive Bayes classifiers through the process of creating our baseline model. We also have begun to learn about the inner workings of RNNs and how to solve the problem types they were designed for. Throughout the rest of the semester, we hope to continue to learn more about how to improve our models in order to more accurately solve our problem.
</p>
<h3>
<a id="support-or-contact" class="anchor" href="#support-or-contact" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Bibliography</h3>
<ul style="list-style-type: none;" id="bibliography">
    <li>[1] Chess Game Dataset (Lichess) https://www.kaggle.com/datasnaek/chess</li>
    <li>[2] Finding Elo https://www.kaggle.com/c/finding-elo </li>
    <li>[3] G. Di Fatta, G. M. Haworth and K. W. Regan, "Skill rating by Bayesian inference," 2009 IEEE Symposium on Computational Intelligence and Data Mining, Nashville, TN, USA, 2009, pp. 89-94, doi: 10.1109/CIDM.2009.4938634.</li>
    <li>[4] Glickman, Mark E., and Albyn C. Jones. (1999) Rating the chess rating system CHANCE-BERLIN THEN NEW YORK12 (1999). 21-28.</li>
    <li>[5] Scheible, Christian and Schutze, Hinrich, “Picking the Amateur’s Mind - Predicting Chess Player Strength from Game Annotations,” The 25th International Conference on Computational Linguistics, pages 311-321, Dublin, Ireland, 2014</li>
</ul>

      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Predicting Chess Ratings from a Single Game maintained by <a href="https://github.gatech.edu/njohnson98">njohnson98</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
